{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d45668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from typing import Callable, List, Dict, NoReturn, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from configure import *\n",
    "from preprocess import *\n",
    "from datasets import (\n",
    "    load_metric,\n",
    "    load_dataset\n",
    ")\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from utils_qa import postprocess_qa_predictions, check_no_error\n",
    "from trainer_qa import QuestionAnsweringTrainer\n",
    "from sparse_retrieval import SparseRetrieval\n",
    "from retrieval_common_part import build_faiss, retrieve_faiss\n",
    "import retrieval_common_part\n",
    "from postprocessing import post_processing_function\n",
    "from run_mrc import run_combine_mrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d59c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH] [--config_name CONFIG_NAME]\n",
      "                             [--tokenizer_name TOKENIZER_NAME] [--run_extraction [RUN_EXTRACTION]] [--no_run_extraction]\n",
      "                             [--run_generation [RUN_GENERATION]] [--dataset_name DATASET_NAME]\n",
      "                             [--overwrite_cache [OVERWRITE_CACHE]] [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]\n",
      "                             [--max_seq_length MAX_SEQ_LENGTH] [--pad_to_max_length [PAD_TO_MAX_LENGTH]]\n",
      "                             [--doc_stride DOC_STRIDE] [--max_answer_length MAX_ANSWER_LENGTH]\n",
      "                             [--eval_retrieval [EVAL_RETRIEVAL]] [--no_eval_retrieval] [--num_clusters NUM_CLUSTERS]\n",
      "                             [--top_k_retrieval TOP_K_RETRIEVAL] [--use_faiss [USE_FAISS]] [--sparse_name SPARSE_NAME]\n",
      "                             [--dense_name DENSE_NAME] [--run_seq2seq [RUN_SEQ2SEQ]] --output_dir OUTPUT_DIR\n",
      "                             [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]] [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]\n",
      "                             [--do_predict [DO_PREDICT]] [--evaluation_strategy {no,steps,epoch}]\n",
      "                             [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
      "                             [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
      "                             [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
      "                             [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
      "                             [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
      "                             [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                             [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS] [--learning_rate LEARNING_RATE]\n",
      "                             [--weight_decay WEIGHT_DECAY] [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
      "                             [--adam_epsilon ADAM_EPSILON] [--max_grad_norm MAX_GRAD_NORM] [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                             [--max_steps MAX_STEPS]\n",
      "                             [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]\n",
      "                             [--warmup_ratio WARMUP_RATIO] [--warmup_steps WARMUP_STEPS]\n",
      "                             [--log_level {debug,info,warning,error,critical,passive}]\n",
      "                             [--log_level_replica {debug,info,warning,error,critical,passive}]\n",
      "                             [--log_on_each_node [LOG_ON_EACH_NODE]] [--no_log_on_each_node] [--logging_dir LOGGING_DIR]\n",
      "                             [--logging_strategy {no,steps,epoch}] [--logging_first_step [LOGGING_FIRST_STEP]]\n",
      "                             [--logging_steps LOGGING_STEPS] [--logging_nan_inf_filter LOGGING_NAN_INF_FILTER]\n",
      "                             [--save_strategy {no,steps,epoch}] [--save_steps SAVE_STEPS] [--save_total_limit SAVE_TOTAL_LIMIT]\n",
      "                             [--save_on_each_node [SAVE_ON_EACH_NODE]] [--no_cuda [NO_CUDA]] [--seed SEED] [--bf16 [BF16]]\n",
      "                             [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL] [--half_precision_backend {auto,amp,apex}]\n",
      "                             [--bf16_full_eval [BF16_FULL_EVAL]] [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 [TF32]]\n",
      "                             [--local_rank LOCAL_RANK] [--xpu_backend {mpi,ccl}] [--tpu_num_cores TPU_NUM_CORES]\n",
      "                             [--tpu_metrics_debug [TPU_METRICS_DEBUG]] [--debug DEBUG]\n",
      "                             [--dataloader_drop_last [DATALOADER_DROP_LAST]] [--eval_steps EVAL_STEPS]\n",
      "                             [--dataloader_num_workers DATALOADER_NUM_WORKERS] [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
      "                             [--disable_tqdm DISABLE_TQDM] [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
      "                             [--no_remove_unused_columns] [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
      "                             [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]] [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
      "                             [--greater_is_better GREATER_IS_BETTER] [--ignore_data_skip [IGNORE_DATA_SKIP]]\n",
      "                             [--sharded_ddp SHARDED_DDP] [--deepspeed DEEPSPEED]\n",
      "                             [--label_smoothing_factor LABEL_SMOOTHING_FACTOR] [--adafactor [ADAFACTOR]]\n",
      "                             [--group_by_length [GROUP_BY_LENGTH]] [--length_column_name LENGTH_COLUMN_NAME]\n",
      "                             [--report_to REPORT_TO [REPORT_TO ...]] [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
      "                             [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]] [--no_dataloader_pin_memory]\n",
      "                             [--skip_memory_metrics [SKIP_MEMORY_METRICS]] [--no_skip_memory_metrics]\n",
      "                             [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]] [--push_to_hub [PUSH_TO_HUB]]\n",
      "                             [--resume_from_checkpoint RESUME_FROM_CHECKPOINT] [--hub_model_id HUB_MODEL_ID]\n",
      "                             [--hub_strategy {end,every_save,checkpoint,all_checkpoints}] [--hub_token HUB_TOKEN]\n",
      "                             [--gradient_checkpointing [GRADIENT_CHECKPOINTING]] [--fp16_backend {auto,amp,apex}]\n",
      "                             [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID] [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]\n",
      "                             [--push_to_hub_token PUSH_TO_HUB_TOKEN] [--mp_parameters MP_PARAMETERS]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --output_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import easydict\n",
    " \n",
    "args = easydict.EasyDict({\n",
    " \n",
    "        \"dataset_name\": '../data/test_dataset',\n",
    " \n",
    "        \"epoch\": 20,\n",
    " \n",
    "        \"gpu\": 0,\n",
    " \n",
    "        \"out\": \"result\",\n",
    " \n",
    "        \"resume\": False,\n",
    " \n",
    "        \"unit\": 1000\n",
    " \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ca5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_dataset('json', data_files={'validation':os.path.join(data_args.dataset_name, 'test.json')}, field='data')\n",
    "\n",
    "# AutoConfig를 이용하여 pretrained model 과 tokenizer를 불러옵니다.\n",
    "# argument로 원하는 모델 이름을 설정하면 옵션을 바꿀 수 있습니다.\n",
    "model, tokenizer = configure_model(model_args, training_args, data_args)\n",
    "\n",
    "# rue일 경우 : run passage retrieval\n",
    "if data_args.eval_retrieval:\n",
    "    datasets = run_retrieval(\n",
    "        tokenizer,\n",
    "        datasets,\n",
    "        training_args,\n",
    "        data_args,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = datasets[\"validation\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d699d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint, max_seq_length = check_no_error(\n",
    "        data_args, training_args, datasets, tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a8cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_args.do_eval or training_args.do_predict:\n",
    "        eval_dataset = datasets[\"validation\"]\n",
    "\n",
    "        prepare_valid_features = preprocess_extract_valid(tokenizer, data_args, column_names, max_seq_length)\n",
    "        # Validation Feature 생성\n",
    "        eval_dataset = eval_dataset.map(\n",
    "            prepare_valid_features,\n",
    "            batched=True,\n",
    "            num_proc=data_args.preprocessing_num_workers,\n",
    "            remove_columns=column_names,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5a3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(\n",
    "        tokenizer, pad_to_multiple_of=8 if training_args.fp16 else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9af75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = QuestionAnsweringTrainer( \n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if training_args.do_train else None,\n",
    "        eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "        eval_examples=datasets[\"validation\"] if training_args.do_eval else None,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        post_process_function=post_processing_function,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57874913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'id'],\n",
      "        num_rows: 9584\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "if training_args.do_predict:\n",
    "        predictions = trainer.predict(\n",
    "            test_dataset=eval_dataset, test_examples=datasets[\"validation\"]\n",
    "        )\n",
    "        # predictions.json 은 postprocess_qa_predictions() 호출시 이미 저장됩니다.\n",
    "        print(\n",
    "            \"No metric can be presented because there is no correct answer given. Job done!\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
